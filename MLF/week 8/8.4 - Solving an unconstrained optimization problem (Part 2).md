# Step Size  
Step size in machine learning context is also known as "Learning Rate".  
It is used to define the distance the minimizing function osccilated in each iteration.  
Step size is a scalar value. Initially we pick an arbitrary value and then tweak it at each iteration.  
$\eta$ is represented as the ste size.  

**General Form:**  
$$x_{t+1} = x_t - \eta_t f'(x_t)$$   

$\rightarrow$ How to choose step size (as a function of t)?  
1. $\eta_0 = 1, \eta_1 = \frac{1}{2}, \dots, \eta_n = \frac{1}{n+1}$  

**General Form:** $\eta_t = \frac{1}{1+t}$  
This is linear and a good choice for step size.  

Step sizes like $\eta_t = \frac{1}{2^t}$ are bad since they are exponent and the sequence may progress very small to close to zero never reaching the minimum.