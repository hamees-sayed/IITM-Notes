# Relation between Primal and Dual Problem, KKT Conditions

### **Primal Problem:**
$$x^* \rightarrow \text{min}_x [\text{max}_{\lambda \geq 0}  L(x, \lambda)]$$

### **Dual Problem:**
$$\lambda^* \rightarrow \text{max}_{\lambda \geq 0} [\text{min}_x  L(x, \lambda)]$$

> $L(x, \lambda) = f(x) + \lambda h(x)$

### **Introduction of Function J:**

$J(x) = \begin{cases}f(x) & \text{if } \space h(x) \leq 0 \\ \infty & \text{otherwise}\end{cases}$

### **Relation between Langragian and $J$:**
Fix $\lambda \geq 0$, then $L(x, \lambda) \leq J(x) \space \forall \space x$
$\text{min}_x L(x, \lambda) \leq \text{min}_x J(x) = f(x^*) \dots$ (Solution of Primal Problem)

$$\text{max}_{\lambda \geq 0}(g(x)) = g(\lambda^*) \leq f(x^*)$$

> **Weak Duality: Value at dual optimum $\leq$ value at primal optimum.**

> **Strong Duality: If $f$ and $h$ are convex. Where $f$ is the objective function and $h$ is the constraint. And $x^*$ and $y^*$ are the primal and dual optimum solutions.**

$$x^* = \text{argmin}_x [\text{max}_{\lambda \geq 0} f(x)+\lambda h(x)], \space \lambda^* = \text{argmax}_{\lambda \geq 0} [\text{min}_x f(x)+\lambda h(x)]$$

By Strong Duality, $f(x^*) = g(x^*) = \text{min}_x [f(x) + \lambda^*h(x)]$

$\therefore \nabla f(x^*) + \lambda^* \nabla h(x^*) = 0$

$\therefore f(x^*) \leq f(x^*)+\lambda^* h(x^*) \leq f(x^*)$

$\therefore \lambda^* h(x^*) = 0$

### **Putting it all Together:**
$f$ & $h$ are convex $\rightarrow$ strong duality.

$x^*, y^*$ must satisfy:
1. $\nabla f(x^*) + \lambda^* \nabla h(x^*) = 0 \dots$ [Stationary Condition, gradient of Lagrangian $(\nabla L(x^*, \lambda^*))$ is zero].
2. $\lambda^* h(x^*) = 0 \dots$ [Complementary Slackness condition, product of Lagrange multiplier and constraint is zero.]
3. $h(x^*) \leq 0 \dots$ [Primary Feasibility.]
4. $\lambda^* \geq 0 \dots$ [Dual Feasibility.]

> **In general, if $(x^*, y^*)$ satisfies the above conditions, then it is a local minima.**

### **KKT (Karush-Kuhn-Tucker) Conditions:**
The KKT conditions are powerful tools to analyze and solve optimization problems, especially in the context of convex optimization. They provide a set of necessary and, under certain conditions, sufficient conditions for optimality.

Given the following objective function and constraints,

$\text{min} f(x) \\ h_i(x) \leq 0 \space \forall \space i = 1, \dots, m \\ l_j (x) = 0 \space \forall \space j = 1, \dots, n$

$L(\textbf{x}, \textbf{u}, \textbf{v}) = f(\textbf{x}) + \sum_{i=1}^m h_i(\textbf{x}) + \sum_{j=1}^n l_j(\textbf{x})$

The KKT conditions are: 
1. $\nabla f(\textbf{x}^*) + \sum_{i=1}^m u_i^* \nabla h_i(\textbf{x}^*) + \sum_{j=1}^n v_j^* \nabla l_j(\textbf{x}^*) = 0 \dots$ [Stationary Condition]  
2. $u_i^*h_i(x^*) = 0 \dots$ [Complementary Slackness condition]
3. $h_i(x^*) \leq 0 \dots$ [Primary Feasibility]
4. $u_i^* \geq 0 \dots$ [Dual Feasibility]